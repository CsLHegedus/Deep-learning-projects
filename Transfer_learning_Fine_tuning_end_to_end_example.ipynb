{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transfer learning Fine tuning end to end example.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VajxgL_vZsvP"
      },
      "source": [
        "\n",
        "This notebook assumes that you have already done feature extraction before\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQ1osY8tZX9W"
      },
      "source": [
        "# import functions\n",
        "import helper_functions\n",
        "from helper_functions import create_tensorboard_callback, plot_loss_curves, unzip_data, walk_through_dir"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27OR30vZcYp5"
      },
      "source": [
        "Initial checks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdA6s2CWcJuR"
      },
      "source": [
        "# Layers in loaded model\n",
        "model_2.layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lw6GkVDIcLPZ"
      },
      "source": [
        "for layer in model_2.layers:\n",
        "  print(layer.trainable)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9EUjA2XcPNB"
      },
      "source": [
        "model_2.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QD9VnVeKcQHh"
      },
      "source": [
        "# How many layers are trainable in our base model?\n",
        "print(len(model_2.layers[2].trainable_variables)) # layer at index 2 is the EfficientNetB0 layer (the base model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKEgbJ_FcRjR"
      },
      "source": [
        "print(len(base_model.trainable_variables))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuS3dA7ccStZ"
      },
      "source": [
        "# Check which layers are tuneable (trainable)\n",
        "for layer_number, layer in enumerate(base_model.layers):\n",
        "  print(layer_number, layer.name, layer.trainable)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nt6-diEvcb6g"
      },
      "source": [
        "Fine tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xORTVd3IcUHJ"
      },
      "source": [
        "base_model.trainable = True\n",
        "\n",
        "# Freeze all layers except for the\n",
        "for layer in base_model.layers[:-10]:\n",
        "  layer.trainable = False\n",
        "\n",
        "# Recompile the model (always recompile after any adjustments to a model)\n",
        "model_2.compile(loss=\"categorical_crossentropy\",\n",
        "              optimizer=tf.keras.optimizers.Adam(lr=0.0001), # lr is 10x lower than before for fine-tuning\n",
        "              metrics=[\"accuracy\"])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAjTMBiHcf6A"
      },
      "source": [
        "# Check  againwhich layers are tuneable (trainable)\n",
        "for layer_number, layer in enumerate(base_model.layers):\n",
        "  print(layer_number, layer.name, layer.trainable)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNmj7VJHcjBY"
      },
      "source": [
        "print(len(model_2.trainable_variables))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmvFWFxIclvA"
      },
      "source": [
        "# Fine tune for another 5 epochs\n",
        "fine_tune_epochs = initial_epochs + 5\n",
        "\n",
        "# Refit the model (same as model_2 except with more trainable layers)\n",
        "history_fine_10_percent_data_aug = model_2.fit(train_data_10_percent,\n",
        "                                               epochs=fine_tune_epochs,\n",
        "                                               validation_data=test_data,\n",
        "                                               initial_epoch=history_10_percent_data_aug.epoch[-1], # start from previous last epoch\n",
        "                                               validation_steps=int(0.25 * len(test_data)),\n",
        "                                               callbacks=[create_tensorboard_callback(\"transfer_learning\", \"10_percent_fine_tune_last_10\")]) # name experiment appropriately\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOH1-rRTcoa4"
      },
      "source": [
        "# Evaluate the model on the test data\n",
        "results_fine_tune_10_percent = model_2.evaluate(test_data)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}